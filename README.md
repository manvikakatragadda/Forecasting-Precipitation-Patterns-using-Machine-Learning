Conducted a comparative analysis of ensemble learning techniques—bagging, boosting, and stacking—to predict precipitation patterns based on historical rainfall data.
Trained individual base models, including Random Forest, XGBoost, Logistic Regression, K-Nearest Neighbors, Decision Tree, Gradient Boosting, AdaBoost, and LightGBM, for performance evaluation.
Implemented stacking, combining base models with meta-models (Logistic Regression, Random Forest, and XGBoost), achieving the highest accuracy (97.0%), followed by bagging (95.3%) and boosting (80.8%).
